// Command databridge-gen generates reflection-free binders for url.Values (forms)
// into your struct types. Prototype: supports flat fields, nested structs,
// basic slices, and common primitives.
//
// Usage:
//
//	go run ./cmd/databridge-gen -types Person,Address -out zz_databridge_gen.go
package main

import (
	"flag"
	"fmt"
	"go/ast"
	"go/format"
	"go/token"
	"log"
	"os"
	"path/filepath"
	"sort"
	"strings"

	"golang.org/x/tools/go/packages"
)

type Field struct {
	Name     string
	JSONName string
	TypeExpr string
	IsPtr    bool
	IsSlice  bool
	ElemExpr string // for slices
	Children []Field
	IsTime   bool
}

func main() {
	var typesCSV string
	var out string
	var pkgDir string
	flag.StringVar(&typesCSV, "types", "", "comma-separated list of type names to generate binders for")
	flag.StringVar(&out, "out", "zz_databridge_gen.go", "output file name")
	flag.StringVar(&pkgDir, "pkgdir", ".", "package directory to load (default: current)")
	flag.Parse()

	if typesCSV == "" {
		log.Fatal("-types is required")
	}
	typeNames := splitCSV(typesCSV)

	cfg := &packages.Config{Mode: packages.NeedName | packages.NeedFiles | packages.NeedCompiledGoFiles | packages.NeedSyntax | packages.NeedTypes | packages.NeedTypesInfo, Dir: pkgDir}
	pkgs, err := packages.Load(cfg, "./")
	if err != nil || packages.PrintErrors(pkgs) > 0 {
		log.Fatalf("failed to load package: %v", err)
	}
	if len(pkgs) == 0 {
		log.Fatal("no package found")
	}
	pkg := pkgs[0]

	// Find package name
	pkgName := pkg.Name

	// Build AST field info by scanning syntax for named types
	fieldsByType := map[string][]Field{}

	for _, f := range pkg.Syntax {
		ast.Inspect(f, func(n ast.Node) bool {
			gd, ok := n.(*ast.GenDecl)
			if !ok || gd.Tok != token.TYPE {
				return true
			}
			for _, spec := range gd.Specs {
				ts, ok := spec.(*ast.TypeSpec)
				if !ok {
					continue
				}
				name := ts.Name.Name
				if !contains(typeNames, name) {
					continue
				}
				st, ok := ts.Type.(*ast.StructType)
				if !ok {
					continue
				}
				fields := collectFields(st.Fields, "")
				fieldsByType[name] = fields
			}
			return false
		})
	}

	// Generate
	var b strings.Builder
	b.WriteString("// Code generated by databridge-gen; DO NOT EDIT.\n")
	b.WriteString("package " + pkgName + "\n\n")
	b.WriteString("import (\n")
	b.WriteString("\t\"net/url\"\n")
	b.WriteString("\t\"strconv\"\n")
	b.WriteString("\t\"time\"\n")
	b.WriteString(")\n\n")

	// helper for bool/int/float parsing and time parsing
	b.WriteString("func _db_parseBool(s string) (bool, error) { return strconv.ParseBool(strings.TrimSpace(s)) }\n")
	b.WriteString("func _db_parseTimeFlexible(s string) (time.Time, bool) {\n")
	b.WriteString("\ts = strings.TrimSpace(s)\n")
	b.WriteString("\tif s == \"\" { return time.Time{}, false }\n")
	b.WriteString("\tformats := []string{time.RFC3339Nano, time.RFC3339, \"2006-01-02 15:04:05\", \"2006-01-02\"}\n")
	b.WriteString("\tfor _, f := range formats { if t, err := time.Parse(f, s); err == nil { return t, true } }\n")
	b.WriteString("\treturn time.Time{}, false\n}\n")
	// strings is needed; we'll ensure import presence if used

	// Build functions for each type
	typeKeys := make([]string, 0, len(fieldsByType))
	for k := range fieldsByType {
		typeKeys = append(typeKeys, k)
	}
	sort.Strings(typeKeys)

	for _, tname := range typeKeys {
		fields := fieldsByType[tname]
		// Ensure strings import present
		// Re-write header to include strings by simply adding it beforehand
		// Already handled below by appending import if needed
		// Generate binder
		b.WriteString(fmt.Sprintf("func Bind%sFromForm(vals url.Values) (%s, error) {\n", tname, tname))
		b.WriteString(fmt.Sprintf("\tout := %s{}\n", tname))
		emitFieldAssignments(&b, "out", "", fields)
		b.WriteString("\treturn out, nil\n}\n\n")
	}

	// patch in missing strings import if used
	outSrc := b.String()
	if strings.Contains(outSrc, "strings.") && !strings.Contains(outSrc, "\"strings\"") {
		outSrc = strings.Replace(outSrc, "import (\n\t\"net/url\"\n", "import (\n\t\"net/url\"\n\t\"strings\"\n", 1)
	}

	// gofmt
	formatted, err := format.Source([]byte(outSrc))
	if err != nil {
		log.Fatalf("format error: %v\nsource:\n%s", err, outSrc)
	}

	// write file
	outPath := out
	if !filepath.IsAbs(outPath) {
		outPath = filepath.Join(pkgDir, out)
	}
	if err := os.WriteFile(outPath, formatted, 0644); err != nil {
		log.Fatalf("write error: %v", err)
	}
}

func splitCSV(s string) []string {
	parts := strings.Split(s, ",")
	out := make([]string, 0, len(parts))
	for _, p := range parts {
		p = strings.TrimSpace(p)
		if p != "" {
			out = append(out, p)
		}
	}
	return out
}

func contains(list []string, v string) bool {
	for _, x := range list {
		if x == v {
			return true
		}
	}
	return false
}

func jsonNameFromTag(tag string, fallback string) string {
	if tag == "" {
		return fallback
	}
	// e.g., `json:"name,omitempty"`
	i := strings.Index(tag, "json:\"")
	if i < 0 {
		return fallback
	}
	rest := tag[i+6:]
	j := strings.Index(rest, "\"")
	if j < 0 {
		return fallback
	}
	value := rest[:j]
	if value == "-" {
		return ""
	}
	// split by comma
	if k := strings.Index(value, ","); k >= 0 {
		value = value[:k]
	}
	if value == "" {
		return fallback
	}
	return value
}

func collectFields(fl *ast.FieldList, parent string) []Field {
	var res []Field
	if fl == nil {
		return res
	}
	for _, f := range fl.List {
		// only named fields (ignore embedded for proto)
		if len(f.Names) == 0 {
			continue
		}
		name := f.Names[0].Name
		// read json tag
		tag := ""
		if f.Tag != nil {
			tag = strings.Trim(f.Tag.Value, "`")
		}
		jname := jsonNameFromTag(tag, name)
		if jname == "" {
			continue
		}

		switch t := f.Type.(type) {
		case *ast.Ident:
			// basic type or named type
			fe := Field{Name: name, JSONName: jname, TypeExpr: t.Name}
			if t.Name == "Time" {
				fe.IsTime = true
			}
			res = append(res, fe)
		case *ast.SelectorExpr:
			// e.g., time.Time
			pkgIdent, ok := t.X.(*ast.Ident)
			if ok && pkgIdent.Name == "time" && t.Sel.Name == "Time" {
				fe := Field{Name: name, JSONName: jname, TypeExpr: "time.Time", IsTime: true}
				res = append(res, fe)
			}
		case *ast.StarExpr:
			switch et := t.X.(type) {
			case *ast.Ident:
				fe := Field{Name: name, JSONName: jname, TypeExpr: et.Name, IsPtr: true}
				if et.Name == "Time" {
					fe.IsTime = true
				}
				res = append(res, fe)
			case *ast.SelectorExpr:
				pkgIdent, ok := et.X.(*ast.Ident)
				if ok && pkgIdent.Name == "time" && et.Sel.Name == "Time" {
					fe := Field{Name: name, JSONName: jname, TypeExpr: "time.Time", IsPtr: true, IsTime: true}
					res = append(res, fe)
				}
			case *ast.StructType:
				// pointer to inline struct
				ch := collectFields(et.Fields, name)
				res = append(res, Field{Name: name, JSONName: jname, TypeExpr: "struct", IsPtr: true, Children: ch})
			}
		case *ast.ArrayType:
			// slice of primitive types (string,int64,float64,bool)
			if ident, ok := t.Elt.(*ast.Ident); ok {
				res = append(res, Field{Name: name, JSONName: jname, TypeExpr: "slice", IsSlice: true, ElemExpr: ident.Name})
			}
		case *ast.StructType:
			// inline struct
			ch := collectFields(t.Fields, name)
			res = append(res, Field{Name: name, JSONName: jname, TypeExpr: "struct", Children: ch})
		}
	}
	return res
}

func emitFieldAssignments(b *strings.Builder, outVar string, prefix string, fields []Field) {
	for _, f := range fields {
		key := f.JSONName
		if prefix != "" {
			key = prefix + "." + key
		}
		switch {
		case f.TypeExpr == "struct":
			// ensure nested struct is addressable
			emitFieldAssignments(b, outVar+"."+f.Name, key, f.Children)
		case f.IsSlice:
			// use all values for the key
			b.WriteString(fmt.Sprintf("\tif vs, ok := vals[%q]; ok {\n", key))
			switch f.ElemExpr {
			case "string":
				b.WriteString(fmt.Sprintf("\t\t%s.%s = make([]string, 0, len(vs))\n", outVar, f.Name))
				b.WriteString(fmt.Sprintf("\t\tfor _, s := range vs { %s.%s = append(%s.%s, s) }\n", outVar, f.Name, outVar, f.Name))
			case "int", "int64":
				b.WriteString(fmt.Sprintf("\t\t%s.%s = make([]int64, 0, len(vs))\n", outVar, f.Name))
				b.WriteString("\t\tfor _, s := range vs { if i, err := strconv.ParseInt(strings.TrimSpace(s), 10, 64); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = append(%s.%s, i)", outVar, f.Name, outVar, f.Name))
				b.WriteString(" } }\n")
			case "float64":
				b.WriteString(fmt.Sprintf("\t\t%s.%s = make([]float64, 0, len(vs))\n", outVar, f.Name))
				b.WriteString("\t\tfor _, s := range vs { if f64, err := strconv.ParseFloat(strings.TrimSpace(s), 64); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = append(%s.%s, f64)", outVar, f.Name, outVar, f.Name))
				b.WriteString(" } }\n")
			case "bool":
				b.WriteString(fmt.Sprintf("\t\t%s.%s = make([]bool, 0, len(vs))\n", outVar, f.Name))
				b.WriteString("\t\tfor _, s := range vs { if b1, err := strconv.ParseBool(strings.TrimSpace(s)); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = append(%s.%s, b1)", outVar, f.Name, outVar, f.Name))
				b.WriteString(" } }\n")
			}
			b.WriteString("\t}\n")
		default:
			// scalar
			b.WriteString(fmt.Sprintf("\tif s := vals.Get(%q); s != \"\" {\n", key))
			switch {
			case f.IsTime:
				b.WriteString("\t\tif tt, ok := _db_parseTimeFlexible(s); ok { ")
				b.WriteString(fmt.Sprintf("%s.%s = tt", outVar, f.Name))
				b.WriteString(" }\n")
			case f.TypeExpr == "string":
				b.WriteString(fmt.Sprintf("\t\t%s.%s = s\n", outVar, f.Name))
			case f.TypeExpr == "bool":
				b.WriteString("\t\tif b1, err := strconv.ParseBool(strings.TrimSpace(s)); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = b1", outVar, f.Name))
				b.WriteString(" }\n")
			case f.TypeExpr == "int" || f.TypeExpr == "int64":
				b.WriteString("\t\tif i, err := strconv.ParseInt(strings.TrimSpace(s), 10, 64); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = i", outVar, f.Name))
				b.WriteString(" }\n")
			case f.TypeExpr == "float64":
				b.WriteString("\t\tif f64, err := strconv.ParseFloat(strings.TrimSpace(s), 64); err == nil { ")
				b.WriteString(fmt.Sprintf("%s.%s = f64", outVar, f.Name))
				b.WriteString(" }\n")
			default:
				// leave unsupported types untouched
			}
			b.WriteString("\t}\n")
		}
	}
}
